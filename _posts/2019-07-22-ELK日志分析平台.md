---
layout: post
title: "Elk日志分析平台"
subtitle: "Elasticsearch + Logstash + Kibana，这三个工具组合形成了一套实用、易用的监控架构。"
author: "zhangshun"
header-img: "img/background/4.jpg"
header-mask: 0.2
tags:
  - Elk
---

### 前言

在运维环境中，管理员通常面对大量的服务器，对于这些服务器的维护，一个很重要的工作就是查看每台服务器的日志信息，如果使用elk，可以将所有的日志集中到一个地方，并且通过图形化、可视化分析日志，实时监控业务状态

### elk日志分析平台架构（三种）

1. datasource -> logstash -> elasticsearch -> kibana
 - 优点：搭建简单，容易上手
 - 缺点：logstash消耗资源大，运行占用cpu和内存高，另外没有消息队列缓存，存在数据丢失隐患
2. datasource -> filebeat -> logstash -> elasticsearch -> kibana
 - 优点：filebeat轻量级开源日志文件数据搜集器，相比logstash，filebeat占用的资源可以忽略不计，解决了logstash占用系统资源较高的问题
 - 缺点：依然没有消息队列缓存，存在数据丢失隐患
3. datasource -> filebeat/logstash -> mq(redis/kafka) -> logstash ->elasticsearch -> kibana
 - 优点：引入了消息队列机制，均衡了网络传输，从而降低了网络闭塞尤其是丢失数据的可能性。

### elasticsearch、logstash、kibana版本

- elasticsearch-7.8.1
- logstash-7.8.1
- kibana-7.8.1
- filebeat-7.8.1

### elasticsearch安装,需要提前安装java

```
Centos:
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-x86_64.rpm
rpm -ivh elasticsearch-7.8.1-x86_64.rpm
systemctl daemon-reload
systemctl enable elasticsearch.service

mkdir -p /data/elk_data
chown elasticsearch:elasticsearch /data/elk_data

修改elasticsearch配置文件
# 集群名称
cluster.name: "es_cluster"
# 节点名称 master1
node.name: master1
# 是否可以成为master节点
node.master: true
# 是否允许该节点存储数据,默认开启
node.data: true
# 网络绑定,这里我绑定 0.0.0.0,支持外网访问
network.host: ["0.0.0.0"]
# 设置对外服务的http端口，默认为9200
http.port: 9200
# 支持跨域访问
http.cors.enabled: true
http.cors.allow-origin: "*"
# 设置节点间交互的tcp端口,默认是9300
transport.tcp.port: 9300
# 集群发现的节点ip
discovery.seed_hosts: ["dc_es1","dc_es2","dc_es3"]
# 手动指定可以成为 mater 的所有节点的 name 或者 ip，这些配置将会在第一次选举中进行计算
cluster.initial_master_nodes: ["dc_es1","dc_es2","dc_es3"]
# 数据仓储位置
path.data: /data/es/data
path.logs: /data/es/logs
# 备份数据存储路径
path.repo: ["/data/es/backup"]
# 用户权限配置，不止的用户的可以忽略，
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.keystore.path: elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: elastic-certificates.p12
# es 应用是不锁住jvm内存
bootstrap.memory_lock: false
bootstrap.system_call_filter: false
indices.query.bool.max_clause_count: 8192
search.max_buckets: 100000

systemctl start elasticsearch.service

运行 Elasticsearch 的密码配置工具，为各种内置用户生成随机的密码。
/usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto


curl http://127.0.0.1:9200
查看本节点的node1信息

curl http://192.168.0.1:9200/_cluster/health?pretty
查看集群的健康情况(green代表集群正常，yellow代表主分片正常、副分片异常，red代表主分片丢失)

curl http://192.168.0.1:9200/_cluster/state?pretty
查看集群的状态信息
```

**安装elasticsearch-head插件**

```
wget https://npm.taobao.org/mirrors/node/latest-v8.x/node-v8.15.0.tar.gz
tar zxvf node-v8.15.0.tar.gz
cd node-v8.15.0
./configure && make && make install

下载phantomjs：
wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2
tar xvjf phantomjs-2.1.1-linux-x86_64.tar.bz2
cd phantomjs-2.1.1-linux-x86_64.tar.bz2/bin
cp phantomjs /usr/local/bin

安装Elasticsearch-head插件
yum install -y git
git clone https://github.com/mobz/elasticsearch-head.git
cd elasticsearch-head
npm install -g grunt --registry=https://registry.npm.taobao.org
npm install
注：如果出现如下提示：说明有漏洞或安全威胁，需执行“npm audit fix”修复

found 24 vulnerabilities (17 low, 1 moderate, 6 high)
  		run `npm audit fix` to fix them, or `npm audit` for details

修改elasticsearch主配置文件
vim /etc/elasticsearch/elasticsearch.yml
http.cors.enabled: true
http.cors.allow-origin: "*"

systemctl restart elasticsearch.service
```

注意：必须在elasticsearch-head目录下启动head插件，进程会读取目录下的Gruntfile.js，否则可能会启动失败。elasticsearch-head监听的端口是9100

```
cd /usr/local/elasticsearch-head
npm run start &			//后台启动
```

通过浏览器访问http://10.0.18.1:9100并连接集群

### logstash安装

```
wget  https://artifacts.elastic.co/downloads/logstash/logstash-7.8.1.rpm
rpm -ivh logstash-7.8.1.rpm
systemctl start logstash.service
ln -s /usr/share/logstash/bin/logstash  /usr/local/bin/

```

### kibana安装

建议每台elasticsearch上面都安装一个kibana，kibana连接自己的elasticsearch，然后通过nginx反向代理到多台kibana，并且在nginx上面也可以做认证。

```
wget https://artifacts.elastic.co/downloads/kibana/kibana-7.8.1-x86_64.rpm
rpm -ivh  kibana-7.8.1-x86_64.rpm
systemctl enable kibana.service

vim /etc/kibana/kibana.yml
server.port: 5601
server.host: "0.0.0.0"
elasticsearch.url: "http://192.168.8.134:9200"
kibana.index: ".kibana"
i18n.locale: "zh-CN"
xpack.security.enabled: true
elasticsearch.username: "kibana_system"
elasticsearch.password: "ChMu94Wyh6zRAfRlRyJM"
elasticsearch.ssl.certificate: /etc/kibana/certs/client.cer
elasticsearch.ssl.key: /etc/kibana/certs/client.key
elasticsearch.ssl.certificateAuthorities: [ "/etc/kibana/certs/client-ca.cer" ]
elasticsearch.ssl.verificationMode: certificate

systemctl start kibana

访问http://192.168.0.1:5601即可访问kibana
```

### filebeat安装

```
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.8.1-x86_64.rpm
rpm -vi filebeat-7.8.1-x86_64.rpm

配置：
vim /etc/filebeat/filebeat.yml
filebeat.inputs:
- type: log
	enabled: true
	paths:
		- /data/logs/localhost_accesslog.*.txt
	tags: ["access_log"]

- type: log
  enabled: true
  paths:
    - /data/logs/alchemy*.log
  tags: ["raptor_applog"]					//logstash可以用tags来分别放入不同的es索引里
  multiline.pattern: '^[A-Z]'				//filebeat的多行合并
  multiline.negate: true
  multiline.match: after

output.logstash:
	hosts: ["192.168.0.248:5044"]
```

### elk安装x-pack插件

```

Logstash:
在output中加入elasticsearch的认证信息
例如：
output {
    if "raptor_access" in [tags] {
        elasticsearch {
            user => "elastic"
	    password => "changeme"
            hosts => "10.31.88.247:9200"
            index => "raptor_access_%{+YYYY.MM}"
        }
    }
}



X-pack中的角色、权限:
watcher_user------授予读取.watches索引，获取观看动作和观察者统计信息的权限
kibana_user------授予Kibana用户所需的最低权限。 此角色授予访问集群的Kibana索引和授予监视权限。
reporting_user------授予使用Kibana所需的X-Pack报告用户所需的特定权限。 这个角色允许访问报告指数。 还应该为报告用户分配kibana_user角色和一个授予他们访问将用于生成报告的数据的角色。
monitoring_user------授予除使用Kibana所需的X-Pack监视用户以外的任何用户所需的最低权限。 这个角色允许访问监控指标。 监控用户也应该分配kibana_user角色
kibana_dashboard_only_user------授予对Kibana仪表板的访问权限以及对.kibana索引的只读权限。 这个角色无法访问Kibana中的编辑工具。
watcher_admin------授予对.watches索引的写入权限，读取对监视历史记录的访问权限和触发的监视索引，并允许执行所有监视器操作
superuser------超级用户
```

### logstash插件

logstash流程可分解为：事件 -> input -> codec -> filter -> codec -> output

```
1、logstash_input_file

input {
	file {
		path => "/var/www/zzc/log/localhost_access_log.*.txt"
		type => "tomcat_access"
		start_position => "beginning"	//beginning或end,默认end
	}
}



2、logstash_output_elasticsearch

output {
	if [type] == "tomcat_access" {
		elasticsearch {
			hosts => ["192.168.0.1:9200","192.168.0.2:9200"]
			index => "tomcat_access-%{+YYYY.MM.dd}"
		}
	}
} 



3、logstash_input_multiline(多行)

input {
	file {
		path => "/data/logs/app*.log"
		type => "tomcat_applog"
		start_position => "beginning"
		codec => multiline {
			pattern => "^\["		//以[开头为分界
			negate => true
			what => 'previous'		//上面的所有内容为一个事件
		}
	}
}



4、logstash_codec_json

如果日志格式为json的,codec_json插件会自动分解json里的字段，并输入

input {
	file {
		path => "/var/www/zzc/log/localhost_access_log.*.txt"
		codec => "json"
		type => "tomcat_access"
	}
}



5、logstash_input_syslog

input {
	syslog {
		type => "system-syslog"
		port => 514
	}
}

监听514端口，接受其他机器传过来的syslog，需要在其他机器上修改一下rsyslog

vim /etc/rsyslog.conf
*.*		@@192.168.0.1:514

*               	//系统日志类型
*	                //日志的level
@@192.168.0.1:514	//传输到192.168.0.1：514端口



6、logstash_input_beats

input {
    beats {
	port => 5044
    }
}



7、logstash_filter_json  filebeat_tags

filter {   
	if "raptor_access" in [tags] {
		json {
			source => "message"
		}
	} 
}

```