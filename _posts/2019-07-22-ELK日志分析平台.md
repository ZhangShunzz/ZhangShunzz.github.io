---
layout: post
title: ELK日志分析平台
date: 2019-07-22 13:30:08
categories: 技术
tag: ELKstack
---

### 前言

在运维环境中，管理员通常面对大量的服务器，对于这些服务器的维护，一个很重要的工作就是查看每台服务器的日志信息，如果使用elk，可以将所有的日志集中到一个地方，并且通过图形化、可视化分析日志，实时监控业务状态

### elk日志分析平台架构（三种）

1. datasource -> logstash -> elasticsearch -> kibana
 - 优点：搭建简单，容易上手
 - 缺点：logstash消耗资源大，运行占用cpu和内存高，另外没有消息队列缓存，存在数据丢失隐患
2. datasource -> filebeat -> logstash -> elasticsearch -> kibana
 - 优点：filebeat轻量级开源日志文件数据搜集器，相比logstash，filebeat占用的资源可以忽略不计，解决了logstash占用系统资源较高的问题
 - 缺点：依然没有消息队列缓存，存在数据丢失隐患
3. datasource -> filebeat/logstash -> mq(redis/kafka) -> logstash ->elasticsearch -> kibana
 - 优点：引入了消息队列机制，均衡了网络传输，从而降低了网络闭塞尤其是丢失数据的可能性。

### elasticsearch、logstash、kibana版本

- elasticsearch-5.6.14
- logstash-6.6.0
- kibana-5.6.14
- filebeat-6.3.2

### elasticsearch安装,需要提前安装java

```
Centos:
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.14.rpm
rpm -ivh elasticsearch-5.6.14.rpm
systemctl daemon-reload
systemctl enable elasticsearch.service

Ubuntu:
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.16.deb
sha1sum elasticsearch-5.6.16.deb 
sudo dpkg -i elasticsearch-5.6.16.deb
service elasticsearch start


修改elasticsearch配置文件
cluster.name: my-elk-culster			//集群名字
node.name: node1						//节点名字
path.data: /data/elk_data				//数据存放路径
path.logs: /var/log/elasticsearch/		//日志存放路径
bootstrap.memory_lock: false			//在启动的时候不锁定内存
network.host: 0.0.0.0					//提供服务绑定的ip地址
http.port: 9200							//监听端口
discovery.zen.ping.unicast.hosts: ["192.168.0.1","192.168.0.2"]	//集群发现通过单播实现


mkdir -p /data/elk_data
chown elasticsearch:elasticsearch /data/elk_data


systemctl start elasticsearch.service

curl http://127.0.0.1:9200
查看本节点的node1信息

curl http://192.168.0.1:9200/_cluster/health?pretty
查看集群的健康情况(green代表集群正常，yellow代表主分片正常、副分片异常，red代表主分片丢失)

curl http://192.168.0.1:9200/_cluster/state?pretty
查看集群的状态信息
```

**安装elasticsearch-head插件**

```
wget https://npm.taobao.org/mirrors/node/latest-v8.x/node-v8.15.0.tar.gz
tar zxvf node-v8.15.0.tar.gz
cd node-v8.15.0
./configure && make && make install

下载phantomjs：
wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2
tar xvjf phantomjs-2.1.1-linux-x86_64.tar.bz2
cd phantomjs-2.1.1-linux-x86_64.tar.bz2/bin
cp phantomjs /usr/local/bin

安装Elasticsearch-head插件
yum install -y git
git clone https://github.com/mobz/elasticsearch-head.git
cd elasticsearch-head
npm install -g grunt --registry=https://registry.npm.taobao.org
npm install
注：如果出现如下提示：说明有漏洞或安全威胁，需执行“npm audit fix”修复

found 24 vulnerabilities (17 low, 1 moderate, 6 high)
  		run `npm audit fix` to fix them, or `npm audit` for details

修改elasticsearch主配置文件
vim /etc/elasticsearch/elasticsearch.yml
http.cors.enabled: true
http.cors.allow-origin: "*"

systemctl restart elasticsearch.service
```

注意：必须在elasticsearch-head目录下启动head插件，进程会读取目录下的Gruntfile.js，否则可能会启动失败。elasticsearch-head监听的端口是9100

```
cd /usr/local/elasticsearch-head
npm run start &			//后台启动
```

通过浏览器访问http://10.0.18.1:9100并连接集群

### logstash安装

```
wget  https://artifacts.elastic.co/downloads/logstash/logstash-6.6.0.rpm
rpm -ivh logstash-6.6.0.rpm
systemctl start logstash.service
ln -s /usr/share/logstash/bin/logstash  /usr/local/bin/

```

### kibana安装

建议每台elasticsearch上面都安装一个kibana，kibana连接自己的elasticsearch，然后通过nginx反向代理到多台kibana，并且在nginx上面也可以做认证。

```
wget https://artifacts.elastic.co/downloads/kibana/kibana-5.6.14-x86_64.rpm
rpm -ivh  kibana-5.6.14-x86_64.rpm
systemctl enable kibana.service

vim /etc/kibana/kibana.yml
server.port: 5601
server.host: "0.0.0.0"
elasticsearch.url: "http://192.168.8.134:9200"
kibana.index: ".kibana"

systemctl start kibana

访问http://192.168.0.1:5601即可访问kibana
```

### filebeat安装

```
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-x86_64.rpm
rpm -vi filebeat-6.3.2-x86_64.rpm

配置：
vim /etc/filebeat/filebeat.yml
filebeat.inputs:
- type: log
	enabled: true
	paths:
		- /data/logs/localhost_accesslog.*.txt
	tags: ["access_log"]

- type: log
  enabled: true
  paths:
    - /data/logs/alchemy*.log
  tags: ["raptor_applog"]					//logstash可以用tags来分别放入不同的es索引里
  multiline.pattern: '^[A-Z]'				//filebeat的多行合并
  multiline.negate: true
  multiline.match: after

output.logstash:
	hosts: ["192.168.0.248:5044"]
```

### elk安装x-pack插件

```
Elasticsearch:
./bin/elasticsearch-plugin install x-pack
vim /etc/elasticsearch/elasticsearch.yml
xpack.security.enabled: true

默认用户名：elastic
默认密码：changeme
修改密码：curl -XPUT -u elastic 'localhost:9200/_xpack/security/user/elastic/_password' -H "ContenType: application/json" -d '{
  "password" : "$PASSWORD"}'



Kibana:
./bin/kibana-plugin install x-pack



Logstash:
在output中加入elasticsearch的认证信息
例如：
output {
    if "raptor_access" in [tags] {
        elasticsearch {
            user => "elastic"
	    password => "changeme"
            hosts => "10.31.88.247:9200"
            index => "raptor_access_%{+YYYY.MM}"
        }
    }
}



X-pack中的角色、权限:
watcher_user------授予读取.watches索引，获取观看动作和观察者统计信息的权限
kibana_user------授予Kibana用户所需的最低权限。 此角色授予访问集群的Kibana索引和授予监视权限。
reporting_user------授予使用Kibana所需的X-Pack报告用户所需的特定权限。 这个角色允许访问报告指数。 还应该为报告用户分配kibana_user角色和一个授予他们访问将用于生成报告的数据的角色。
monitoring_user------授予除使用Kibana所需的X-Pack监视用户以外的任何用户所需的最低权限。 这个角色允许访问监控指标。 监控用户也应该分配kibana_user角色
kibana_dashboard_only_user------授予对Kibana仪表板的访问权限以及对.kibana索引的只读权限。 这个角色无法访问Kibana中的编辑工具。
watcher_admin------授予对.watches索引的写入权限，读取对监视历史记录的访问权限和触发的监视索引，并允许执行所有监视器操作
superuser------超级用户
```

### logstash插件

logstash流程可分解为：事件 -> input -> codec -> filter -> codec -> output

```
1、logstash_input_file

input {
	file {
		path => "/var/www/zzc/log/localhost_access_log.*.txt"
		type => "tomcat_access"
		start_position => "beginning"	//beginning或end,默认end
	}
}



2、logstash_output_elasticsearch

output {
	if [type] == "tomcat_access" {
		elasticsearch {
			hosts => ["192.168.0.1:9200","192.168.0.2:9200"]
			index => "tomcat_access-%{+YYYY.MM.dd}"
		}
	}
} 



3、logstash_input_multiline(多行)

input {
	file {
		path => "/data/logs/app*.log"
		type => "tomcat_applog"
		start_position => "beginning"
		codec => multiline {
			pattern => "^\["		//以[开头为分界
			negate => true
			what => 'previous'		//上面的所有内容为一个事件
		}
	}
}



4、logstash_codec_json

如果日志格式为json的,codec_json插件会自动分解json里的字段，并输入

input {
	file {
		path => "/var/www/zzc/log/localhost_access_log.*.txt"
		codec => "json"
		type => "tomcat_access"
	}
}



5、logstash_input_syslog

input {
	syslog {
		type => "system-syslog"
		port => 514
	}
}

监听514端口，接受其他机器传过来的syslog，需要在其他机器上修改一下rsyslog

vim /etc/rsyslog.conf
*.*		@@192.168.0.1:514

*               	//系统日志类型
*	                //日志的level
@@192.168.0.1:514	//传输到192.168.0.1：514端口



6、logstash_input_beats

input {
    beats {
	port => 5044
    }
}



7、logstash_filter_json  filebeat_tags

filter {   
	if "raptor_access" in [tags] {
		json {
			source => "message"
		}
	} 
}

```