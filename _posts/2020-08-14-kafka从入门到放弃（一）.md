---
layout: post
title: "Kafka：从入门到放弃（一）"
author: "zhangshun"
header-img: "img/background/15.jpg"
header-mask: 0.2
tags:
  - Kafka
---

### 1、Kafka概述

**1.1 定义**

Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。

**1.2 消息队列**

**1.2.1 传统消息队列的应用场景**

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/消息队列应用场景.png)

使用消息队列的好处

1）解耦

允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束

2）可恢复性

系统的一部分组件失效时，不会影响整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。

3）缓冲

有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。

4）灵活性 & 峰值处理能力

在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

5）异步通信

很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

**1.2.2 消息队列的两种模式**

（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）

消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。消息被消费以后，queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/消息队列点对点模式.png)

（2）发布/订阅模式（一对多，消费者消费数据之后不会清除消息）

消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/消息队列发布订阅模式.png)

**1.3 Kafka基础架构**

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/kafka基础架构.png)

1 ）Producer：消息生产者，就是向kafka broker发消息的客户端；

2 ）Consumer：消息消费者，向kafka broker取消息的客户端；

3 ）Consumer Group（CG ）：消费者组，由多个consumer组成。 消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个 组内 消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即 消费者组是逻辑上的一个订阅者。

4 ）Broker：一台 kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。

5 ）Topic：可以理解为一个队列，生产者和消费者面向的都是一个topic；

6 ）Partition：为了实现扩展性，一个非常大的topic可以分布到多个 broker（即服务器）上，一个 topic可以分为多个partition，每个 partition是一个有序的队列；

7）Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。

8）leader：每个分区多个副本的“主”，生产者发送消息的对象，以及消费者消费数据的对象都是leader。

9）follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader。

### 2、Kafka快速入门

**2.1 安装部署**

**2.2 Kafka命令行操作**

### 3、Kafka架构深入

**3.1 Kafka工作流程及文件存储机制**

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/kafka工作流程.png)

Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。

topic是逻辑上的概念，而partition是物理上的概念，每个partition对应一个log文件夹，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/kafka文件存储机制.png)

由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引的机制，将每个partition分为多个segment。每个segment对应两个文件————".index"文件和".log"文件。这些文件位于一个文件夹下，该文件夹的命名规则是：topic名称+分区序列号。例如，first这个topic有三个分区，则其对应的文件夹为first-0，first-1，first-2。

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/partiti中index-log文件.png)

index和log以当前segment的第一条消息的offset命名。下图为index文件和log文件的结构示意图。

![](/img/in-post/2020-08-14-kafka从入门到放弃（一）/pindex文件和log文件详解.png)

".index"文件存储大量的索引信息，".log"文件存储大量的数据，索引文件中的元数据指向对应数据文件中的message的物理偏移量。